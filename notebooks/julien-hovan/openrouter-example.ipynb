{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding OpenRouter and LangChain Integration\n",
    "\n",
    "OpenRouter is an exciting platform that acts as a universal gateway to various AI language models. \n",
    "Think of it as a \"smart router\" that connects you to models from providers like OpenAI, Anthropic, \n",
    "and Google through a single, unified interface.\n",
    "\n",
    "In this tutorial, we'll explore:\n",
    "1. What OpenRouter is and why it's useful\n",
    "2. How to connect it with LangChain's ChatOpenAI\n",
    "3. Building practical examples using this integration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### What is OpenRouter? ü§î\n",
    "\n",
    "Imagine you're a developer wanting to use different AI models in your application. Traditionally, \n",
    "you'd need to:\n",
    "- Sign up with each AI provider separately\n",
    "- Manage multiple API keys\n",
    "- Learn different API interfaces\n",
    "- Handle various authentication methods\n",
    "\n",
    "OpenRouter simplifies this by providing:\n",
    "1. ‚ú® One API to access them all: Use a single API key and interface\n",
    "2. üéØ Model flexibility: Choose from various AI models based on your needs\n",
    "3. üîå Easy integration: Works seamlessly with popular tools like LangChain\n",
    "\n",
    "The best part? It's compatible with LangChain's ChatOpenAI module, making it a powerful tool \n",
    "for building AI applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Setting Up OpenRouter with LangChain üõ†Ô∏è\n",
    "\n",
    "To use OpenRouter with LangChain's ChatOpenAI module, we need to configure two key attributes:\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "1. base_url: Set to OpenRouter's API endpoint\n",
    "base_url = \"https://openrouter.ai/api/v1\"\n",
    "\n",
    "2. api_key: Your OpenRouter API key (get one at https://openrouter.ai)\n",
    "You can set this through environment variables or directly\n",
    "\n",
    "#### Initialize ChatOpenAI with OpenRouter configuration\n",
    "```python\n",
    "chat = ChatOpenAI(\n",
    "    base_url=base_url,\n",
    "    api_key=\"your-openrouter-api-key\",  # Replace with your actual API key\n",
    "    model=\"anthropic/claude-3-sonnet\"    # Specify any supported OpenRouter model\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "# Load environment variables\n",
    "dotenv.load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI \n",
    "from pydantic import SecretStr\n",
    "\n",
    "base_url = \"https://openrouter.ai/api/v1\"\n",
    "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    base_url=base_url,\n",
    "    api_key=SecretStr(api_key), \n",
    "    model=\"google/gemma-2-9b-it:free\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is **Paris**. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat.invoke(\"What is the capital of France?\")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ChatOpenRouter class to interact with OpenRouter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatOpenRouter Tutorial\n",
    "# ======================\n",
    "import sys \n",
    "import os\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage \n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(os.path.dirname(\".\")))))\n",
    "from routers.chat_openrouter import ChatOpenRouter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Models in OpenRouter:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['google/gemma-2-9b-it:free',\n",
       " 'liquid/lfm-40b:free',\n",
       " 'nousresearch/hermes-3-llama-3.1-405b:free',\n",
       " 'meta-llama/llama-3.1-405b-instruct:free',\n",
       " 'gryphe/mythomax-l2-13b:free']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Available Models\n",
    "# ------------------\n",
    "print(\"Available Models in OpenRouter:\")\n",
    "ChatOpenRouter.list_supported_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 21:16:38,091 - httpx - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simple Response:\n",
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. Basic Usage\n",
    "# -------------\n",
    "# Initialize the router with a specific model\n",
    "router = ChatOpenRouter(model_name=\"liquid/lfm-40b:free\")\n",
    "\n",
    "# Simple single message interaction\n",
    "response = router.invoke(\"What is the capital of France?\")\n",
    "print(\"\\nSimple Response:\")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 21:16:43,470 - httpx - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response with System Context:\n",
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. Working with Message Chains\n",
    "# ----------------------------\n",
    "# Initialize a conversation with a system message and a human message\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant who is knowledgeable about world capitals.\"),\n",
    "    HumanMessage(content=\"What is the capital of France?\")\n",
    "]\n",
    "\n",
    "# Send the message chain\n",
    "response = router.invoke(messages)\n",
    "print(\"\\nResponse with System Context:\")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 21:17:17,520 - httpx - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multi-turn Conversation Response:\n",
      "The capital of Germany is Berlin.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4. Building a Conversation\n",
    "# ------------------------\n",
    "# Let's create a multi-turn conversation\n",
    "conversation = [\n",
    "    SystemMessage(content=\"You are a helpful assistant who is knowledgeable about world capitals.\"),\n",
    "    HumanMessage(content=\"What is the capital of France?\"),\n",
    "    AIMessage(content=\"The capital of France is Paris.\"),\n",
    "    HumanMessage(content=\"What about Germany?\")\n",
    "]\n",
    "\n",
    "response = router.invoke(conversation)\n",
    "print(\"\\nMulti-turn Conversation Response:\")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5. Async Usage (if needed)\n",
    "# ------------------------\n",
    "async def async_example():\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "        HumanMessage(content=\"Tell me a fun fact about Paris.\")\n",
    "    ]\n",
    "    response = await router.agenerate_with_retry(messages)\n",
    "    return response\n",
    "\n",
    "# To run async code in Jupyter:\n",
    "# import asyncio\n",
    "# await async_example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
